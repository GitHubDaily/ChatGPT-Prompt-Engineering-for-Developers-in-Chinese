1
00:00:05,000 --> 00:00:09,000
歡迎學習《開發者的 ChatGPT Prompt 工程》課程

2
00:00:09,000 --> 00:00:14,000
很高興能邀請到 Isa Fulford 和我一起授課

3
00:00:14,000 --> 00:00:18,000
她是 OpenAI 的技術人員之一，曾建立了流行的

4
00:00:18,000 --> 00:00:23,000
ChatGPT 搜尋插件，她大部分工作是教人們

5
00:00:23,000 --> 00:00:27,000
如何在產品中使用 LLM 或大語言模型技術

6
00:00:27,000 --> 00:00:31,000
她還為 OpenAI 手冊做出了貢獻，教會人們如何使用提示詞

7
00:00:31,000 --> 00:00:32,000
所以，很高興有你參與

8
00:00:32,000 --> 00:00:37,000
我也很高興能在這裡與大家分享一些提示詞的最佳實踐

9
00:00:37,000 --> 00:00:42,000
在網路上有很多關於提示詞資料以及一些文章

10
00:00:42,000 --> 00:00:45,000
比如，每個人都必須知道的30個提示詞

11
00:00:45,000 --> 00:00:50,000
許多人正在使用 ChatGPT 的 Web 使用者介面

12
00:00:50,000 --> 00:00:54,000
來完成特定而且通常是一次性的任務

13
00:00:54,000 --> 00:01:00,000
但作為一名開發者，我認為 LLMs 和大語言模型的強大也是不可忽視的

14
00:01:00,000 --> 00:01:04,000
那就是透過 API 利用 LLM 來快速構建軟體應用程式

15
00:01:04,000 --> 00:01:08,000
我認為這仍然被嚴重低估

16
00:01:08,000 --> 00:01:12,000
事實上，我在 AI Fund 的團隊，也就是Deep Learning.AI 的姐妹公司

17
00:01:12,000 --> 00:01:16,000
一直在與許多新創公司、不同計劃合作

18
00:01:16,000 --> 00:01:18,000
來應用這些技術

19
00:01:18,000 --> 00:01:23,000
看到 LLM API 能夠讓開發者快速建立一些東西

20
00:01:23,000 --> 00:01:25,000
這很令人興奮

21
00:01:25,000 --> 00:01:29,000
所以在這個課程中，我們將與你分享一些可能性

22
00:01:29,000 --> 00:01:34,000
你可以做什麼，以及如何做的最佳實踐

23
00:01:34,000 --> 00:01:36,000
這裡會涵蓋很多資料

24
00:01:36,000 --> 00:01:41,000
首先，你將學習一些軟體開發的提示詞最佳實踐

25
00:01:41,000 --> 00:01:45,000
然後，我們將涵蓋一些常見的案例、總結、推斷

26
00:01:45,000 --> 00:01:50,000
轉化、擴展，然後使用 LLM 建立一個聊天機器人

27
00:01:50,000 --> 00:01:53,000
我們希望這將激發你

28
00:01:53,000 --> 00:01:55,000
開發新應用程式的想像力

29
00:01:55,000 --> 00:01:58,000
因此，在大型語言模型或 LLM 的發展中

30
00:01:58,000 --> 00:02:02,000
大體上有兩種類型的 LLM，我把它們稱為

31
00:02:02,000 --> 00:02:06,000
基礎 LLM 和指令學習 LLM

32
00:02:06,000 --> 00:02:11,000
基礎 LLM 已經被訓練成基於文字訓練資料來預測下一個單詞

33
00:02:11,000 --> 00:02:15,000
通常透過網路和其他來源訓練大量資料

34
00:02:15,000 --> 00:02:19,000
並計算出下一個最可能出現的詞是什麼

35
00:02:19,000 --> 00:02:24,000
比如，你輸入這個提示詞："從前有一隻獨角獸"

36
00:02:24,000 --> 00:02:28,000
它會進行自動完成，並預測接下來的幾個詞是

37
00:02:28,000 --> 00:02:31,000
"和所有獨角獸朋友一起生活在一個神奇的森林裡"

38
00:02:31,000 --> 00:02:35,000
但是如果你是用"法國的首都是什?"作為提示詞

39
00:02:35,000 --> 00:02:40,000
根據網路上的文章

40
00:02:40,000 --> 00:02:44,000
很有可能是，基礎 LLM 會以下列方式完成這個任務

41
00:02:44,000 --> 00:02:48,000
法國最大的城市是哪 ? 法國的人口有多少 ? 等

42
00:02:48,000 --> 00:02:52,000
因為網路上的文章，可能會列出

43
00:02:52,000 --> 00:02:55,000
關於法國的小測驗問題列表

44
00:02:55,000 --> 00:03:00,000
與此相反，指令學習 LLM ，發展態勢較猛

45
00:03:00,000 --> 00:03:04,000
LLM 的研究和實踐一直在進行

46
00:03:04,000 --> 00:03:08,000
一個經過指令學習的 LLM 已經被訓練得能夠遵循指令

47
00:03:08,000 --> 00:03:11,000
因此，如果你問它，法國的首都在哪？

48
00:03:11,000 --> 00:03:15,000
它很可能輸出法國的首都是巴黎

49
00:03:15,000 --> 00:03:19,000
因此，指令學習 LLM 的典型訓練方式是

50
00:03:19,000 --> 00:03:23,000
從一個在大量文字資料上訓練過的基礎LLM 開始

51
00:03:23,000 --> 00:03:28,000
然後進一步訓練它，用輸入和輸出來進一步微調它

52
00:03:28,000 --> 00:03:32,000
這些輸入和輸出都是指令，也是遵循這些指令的良好嘗試

53
00:03:32,000 --> 00:03:36,000
然後經常使用一種叫做 RLHF 的技術進一步完善

54
00:03:36,000 --> 00:03:41,000
從人類反饋中進行強化學習，以使系統能夠更好地

55
00:03:41,000 --> 00:03:43,000
提供幫助並遵循指令

56
00:03:43,000 --> 00:03:47,000
因為經過指令學習的 LLM 已經被訓練得很有幫助

57
00:03:47,000 --> 00:03:51,000
誠實且無害，因此，舉例來說，它們不太可能輸出

58
00:03:51,000 --> 00:03:55,000
那些與基礎 LLM 相比，會出問題的文字，如有害的輸出

59
00:03:55,000 --> 00:03:59,000
很多實際應用場景已經開始向

60
00:03:59,000 --> 00:04:01,000
指令學習 LLM 轉移

61
00:04:01,000 --> 00:04:04,000
你在網路上找到的一些最佳實踐可能更適用於基礎 LLM

62
00:04:04,000 --> 00:04:08,000
但對於今天的大多數實際應用情況來說，它們可能不太合適

63
00:04:08,000 --> 00:04:13,000
我們建議大多數人多關注指令學習 LLM

64
00:04:13,000 --> 00:04:17,000
它們更容易使用，而且由於 OpenAI

65
00:04:17,000 --> 00:04:22,000
和其他 LLM 公司的工作，也將變得更加安全和一致

66
00:04:22,000 --> 00:04:27,000
因此，本課程將重點介紹指令學習LLM的最佳實踐

67
00:04:27,000 --> 00:04:32,000
這也是我們建議你在大多數應用程式中使用的

68
00:04:32,000 --> 00:04:36,000
在繼續之前，我想感謝來自 OpenAI

69
00:04:36,000 --> 00:04:39,000
和 DeepLearning.ai 的團隊

70
00:04:39,000 --> 00:04:42,000
他們為我和 Isa 將要介紹的資料做出了貢獻

71
00:04:42,000 --> 00:04:45,000
我非常感謝 Andrew Main, Joe Palermo, Boris Power

72
00:04:45,000 --> 00:04:49,000
Ted Sanders，以及來自 OpenAI 的 Lilian Wang

73
00:04:49,000 --> 00:04:53,000
與我們一起集思廣益，審核資料

74
00:04:53,000 --> 00:04:55,000
並做成這個簡短的課程

75
00:04:55,000 --> 00:04:58,000
我也很感謝 DeepLearning 的工作

76
00:04:58,000 --> 00:05:01,000
Jeff Ludwig、Eddie Hsu 和 Tommy Nelson 的工作

77
00:05:01,000 --> 00:05:06,000
因此，當你使用一個指令學習 LLM 時，可以將其看作是

78
00:05:06,000 --> 00:05:10,000
向另一個人發出指令，比如一個聰明但不知道

79
00:05:10,000 --> 00:05:12,000
任務細節的人

80
00:05:12,000 --> 00:05:16,000
因此，當一個 LLM 做得不好時，有時是因為指令

81
00:05:16,000 --> 00:05:17,000
不夠清楚

82
00:05:17,000 --> 00:05:20,000
例如，如果你說，請給我寫一些

83
00:05:20,000 --> 00:05:22,000
關於艾倫圖靈的東西

84
00:05:22,000 --> 00:05:26,000
那除此之外，明確描述以下幾點也會有所幫助

85
00:05:26,000 --> 00:05:30,000
你想讓文章側重於他的科學工作

86
00:05:30,000 --> 00:05:34,000
他的個人生活、他在歷史上的角色或其他方向

87
00:05:34,000 --> 00:05:39,000
如果你指定想要文字的語調

88
00:05:39,000 --> 00:05:43,000
它是否會根據指定的語調來寫，比如像專業記者寫的那樣

89
00:05:43,000 --> 00:05:46,000
還是更像隨手寫給朋友的輕鬆語氣

90
00:05:46,000 --> 00:05:47,000
這會協助

91
00:05:47,000 --> 00:05:49,000
LLM 產生你想要的東西

92
00:05:49,000 --> 00:05:52,000
當然，如果你想像是自己在問，比如

93
00:05:52,000 --> 00:05:56,000
一個剛畢業的大學生為你完成這項任務

94
00:05:56,000 --> 00:05:59,000
如果你甚至可以指定他們應該閱讀哪些文字片段

95
00:05:59,000 --> 00:06:02,000
提前寫出這篇關於艾倫圖靈的文章

96
00:06:02,000 --> 00:06:06,000
這能成功讓那個剛畢業的大學生

97
00:06:06,000 --> 00:06:09,000
更好的為你完成這項任務

98
00:06:09,000 --> 00:06:13,000
因此，在接下來的影片中，你會看到如何清晰且明確

99
00:06:13,000 --> 00:06:17,000
描述提示詞，這是一個重要的 LLM 提示詞準則

100
00:06:17,000 --> 00:06:21,000
而且你還將從 Isa 那裡學習第二個提示詞準則

101
00:06:21,000 --> 00:06:24,000
那就是給 LLM 時間來思考

102
00:06:24,000 --> 00:06:29,000
因此，讓我們繼續觀看下一個影片
